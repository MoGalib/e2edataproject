{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\nimport tensorflow as tf\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "cell2",
    "codeCollapsed": false
   },
   "source": "USE DATABASE snowflakegold;\nUSE SCHEMA gold_layer;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "sql",
    "name": "cell3",
    "codeCollapsed": false
   },
   "source": "SHOW TABLES IN SCHEMA gold_layer;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5fdda6d4-c9c3-4daa-946e-62060c59ecb6",
   "metadata": {
    "language": "python",
    "name": "cell4",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "query = \"select * from sales_order_details\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "af846a74-136b-4813-ac1a-547517f5da6b",
   "metadata": {
    "language": "python",
    "name": "cell5",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "df = session.sql(query).to_pandas()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fb12cb5c-bbf1-4f6f-b43a-8101ac43bb5c",
   "metadata": {
    "language": "python",
    "name": "cell6",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b94b4d0f-dea0-4073-a8ba-0cd527f1b76c",
   "metadata": {
    "language": "python",
    "name": "cell8",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "X = df[['UNIT_PRICE', 'PRODUCT_ID']]\ny = df['ORDER_QTY']  # This represents demand",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "10641f34-c9fd-4d05-bd2a-93f2f1671c60",
   "metadata": {
    "language": "python",
    "name": "cell7",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Split the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e25f9b46-873e-41d2-872e-a23ad8cdcb13",
   "metadata": {
    "language": "python",
    "name": "cell9",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Scale the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d99bd321-5283-4d5d-8a9d-87de807e8996",
   "metadata": {
    "language": "python",
    "name": "cell10",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Build the model\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=(X_train_scaled.shape[1],)),  # Input layer\n    tf.keras.layers.Dense(64, activation='relu'),               # Hidden layer 1\n    tf.keras.layers.Dense(32, activation='relu'),               # Hidden layer 2\n    tf.keras.layers.Dense(1)                                    # Output layer for regression\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c3bfe10a-9563-489f-9755-2799af6de5e3",
   "metadata": {
    "language": "python",
    "name": "cell11",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Train the model\nhistory = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dd576b69-2b7f-4033-93b3-eeec7f2f43a4",
   "metadata": {
    "language": "python",
    "name": "cell12",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Evaluate the model on the test set\ntest_loss = model.evaluate(X_test_scaled, y_test)\nprint(f'Test Loss: {test_loss}')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7636b826-fba3-4da2-b2e3-3925656a9581",
   "metadata": {
    "language": "python",
    "name": "cell13",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Make predictions on the test set\npredictions = model.predict(X_test_scaled)\n# Round off the predictions\nrounded_predictions = np.round(predictions).astype(int)  # Convert to integers if necessary\n# Convert predictions to a DataFrame for easy comparison\npredictions_df = pd.DataFrame({\n    'Actual': y_test,\n    'Predicted': rounded_predictions.flatten()\n})\n\n# Display the first few rows of the predictions\nprint(predictions_df.head())\n",
   "execution_count": null
  }
 ]
}